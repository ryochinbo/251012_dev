{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "230bb19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "from pypdf import PdfReader\n",
    "import markdown\n",
    "from unstructured.partition.text import partition_text\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0019cee",
   "metadata": {},
   "source": [
    "## cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3feaf393",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "currentdir = os.getcwd()\n",
    "input_dir = \"../data/1020test/raw\" # 入力ディレクトリ\n",
    "persist_db_dir = \"../data/1020test/vector_store\" # データベースの保存ディレクトリ\n",
    "collection_name = \"1020_test\" # コレクション名\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e230232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .envファイルからAPIキーを読み込む\n",
    "env_path = os.path.join(currentdir, '..', 'configs', '.env')\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"geminiapikey\")\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"GEMINI_API_KEYが見つかりません。../configs/.envファイルを確認してください。\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "245e4513",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = \"gemini-2.5-flash\"\n",
    "embed_model = \"gemini-embedding-001\"\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6854f29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI learns patterns from data to make informed predictions or decisions.\n"
     ]
    }
   ],
   "source": [
    "### api access check\n",
    "response = client.models.generate_content(\n",
    "    model=chat_model, contents=\"Explain how AI works in a few words\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82761867",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28db3c05",
   "metadata": {},
   "source": [
    "## test用コード  \n",
    "こちらは検証用にデータベース蓄積用の文書ファイルを仮で作成するためのコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fa454f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'../data/1020test/raw' ディレクトリを作成しました。この中にPDFやMarkdownファイルを入れてください。\n",
      "ダミーファイルを生成します...\n",
      "ダミーファイルの生成が完了しました。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# input_dirが存在しない場合は作成し、ダミーファイルを生成\n",
    "if not os.path.exists(input_dir):\n",
    "    os.makedirs(input_dir)\n",
    "    print(f\"'{input_dir}' ディレクトリを作成しました。この中にPDFやMarkdownファイルを入れてください。\")\n",
    "    print(\"ダミーファイルを生成します...\")\n",
    "\n",
    "    md_example_path = os.path.join(input_dir, \"example_doc1.md\")\n",
    "    md_example_path_2 = os.path.join(input_dir, \"example_doc2.md\")\n",
    "\n",
    "\n",
    "    with open(md_example_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# Gemini APIの概要\\n\\n\")\n",
    "        f.write(\"Gemini APIは、Googleの最新のマルチモーダルAIモデルであるGeminiモデルへのアクセスを提供します。\\n\")\n",
    "        f.write(\"これは、テキスト、画像、音声、動画などの異なるタイプの情報を理解し、処理することができます。\\n\\n\")\n",
    "        f.write(\"## 主な機能\\n\\n\")\n",
    "        f.write(\"*   **柔軟なモデル:** さまざまな規模のモデル（Ultra, Pro, Nano）があります。\\n\")\n",
    "        f.write(\"*   **マルチモーダル:** テキストだけでなく、画像などの入力も扱えます。\\n\")\n",
    "        f.write(\"*   **高度な推論:** 複雑な問題解決能力を持っています。\\n\\n\")\n",
    "        f.write(\"RAG (Retrieval Augmented Generation) は、外部知識ベースから情報を取得し、その情報に基づいて応答を生成するAIシステムです。\\n\")\n",
    "        f.write(\"これにより、モデルはより正確で最新の情報を利用できます。質問応答システムによく用いられます。\\n\")\n",
    "\n",
    "    with open(md_example_path_2, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# ベクトルデータベースについて\\n\\n\")\n",
    "        f.write(\"ベクトルデータベースは、データを高次元のベクトル表現として保存し、類似性検索を効率的に行うためのデータベースです。\\n\")\n",
    "        f.write(\"特にAIや機械学習の分野で、意味的に関連する情報を素早く見つけ出すのに役立ちます。\\n\\n\")\n",
    "        f.write(\"## 利点\\n\\n\")\n",
    "        f.write(\"*   **高速な類似性検索:** ユークリッド距離やコサイン類似度などの指標で類似度を計算します。\\n\")\n",
    "        f.write(\"*   **スケーラビリティ:** 大規模なデータセットにも対応できます。\\n\")\n",
    "        f.write(\"*   **セマンティック検索:** キーワードだけでなく、意味に基づいた検索が可能です。\\n\")\n",
    "        f.write(\"ChromaDBは、Pythonで簡単に利用できる軽量なベクトルデータベースであり、RAGシステムの実装に適しています。\\n\")\n",
    "    print(\"ダミーファイルの生成が完了しました。\")\n",
    "else:\n",
    "    print(f\"'{input_dir}' ディレクトリは既に存在します。既存のファイルを使用します。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac694407",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaa1346",
   "metadata": {},
   "source": [
    "## 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c66b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- ドキュメントの読み込みとチャンク化 ---\n",
    "\n",
    "def load_document(file_path):\n",
    "    \"\"\"ファイルパスに基づいてPDFまたはMarkdownファイルを読み込む\"\"\"\n",
    "    _, ext = os.path.splitext(file_path)\n",
    "    text_content = \"\"\n",
    "\n",
    "    if ext.lower() == \".pdf\":\n",
    "        try:\n",
    "            reader = PdfReader(file_path)\n",
    "            for page in reader.pages:\n",
    "                text_content += page.extract_text() if page.extract_text() else \"\"\n",
    "        except Exception as e:\n",
    "            print(f\"PDFファイル '{file_path}' の読み込み中にエラーが発生しました: {e}\")\n",
    "            return None\n",
    "    elif ext.lower() == \".md\":\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                md_content = f.read()\n",
    "                text_content = markdown.markdown(md_content) \n",
    "                elements = partition_text(text=text_content, chunk_elements_by_title=False)\n",
    "                text_content = \"\\n\".join([str(el) for el in elements])\n",
    "        except Exception as e:\n",
    "            print(f\"Markdownファイル '{file_path}' の読み込み中にエラーが発生しました: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"サポートされていないファイル形式です: {file_path}\")\n",
    "        return None\n",
    "    return text_content\n",
    "\n",
    "def chunk_text(text, chunk_size=1000, overlap_size=100):\n",
    "    \"\"\"テキストをチャンクに分割する\"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        if end >= len(text):\n",
    "            break\n",
    "        start += (chunk_size - overlap_size)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe9371ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- ベクトルデータベースの作成と保存 (ChromaDB) ---\n",
    "\n",
    "def create_vector_database(documents_data, collection_name=\"my_rag_collection\", persist_directory=\"./chroma_db\"):\n",
    "    \"\"\"\n",
    "    複数のドキュメントからベクトルデータベースを作成し、永続化する\n",
    "    documents_data は [(ファイルパス, テキストコンテンツ), ...] のリスト\n",
    "    \"\"\"\n",
    "    all_chunks = []\n",
    "    all_ids = []\n",
    "    all_metadatas = []\n",
    "    global_chunk_id = 0\n",
    "\n",
    "    print(f\"ベクトルデータベース '{collection_name}' を作成中...\")\n",
    "\n",
    "    client = chromadb.PersistentClient(path=persist_directory)\n",
    "    gemini_ef = embedding_functions.GoogleGenerativeAiEmbeddingFunction(\n",
    "        api_key=GEMINI_API_KEY, model_name=embed_model\n",
    "    )\n",
    "    collection = client.get_or_create_collection(name=collection_name, embedding_function=gemini_ef)\n",
    "\n",
    "    current_doc_count = collection.count()\n",
    "    print(f\"既存のコレクション '{collection_name}' には {current_doc_count} 個のドキュメントがあります。\")\n",
    "    \n",
    "    for file_path, full_text in documents_data:\n",
    "        if full_text:\n",
    "            chunks = chunk_text(full_text)\n",
    "            print(f\"ファイル '{file_path}' を {len(chunks)} 個のチャンクに分割しました。\")\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                all_chunks.append(chunk)\n",
    "                all_ids.append(f\"doc_chunk_{global_chunk_id}\")\n",
    "                all_metadatas.append({\"source\": os.path.basename(file_path), \"chunk_id\": i, \"file_path\": file_path})\n",
    "                global_chunk_id += 1\n",
    "        else:\n",
    "            print(f\"ファイル '{file_path}' のテキストコンテンツが空のため、スキップします。\")\n",
    "\n",
    "    if not all_chunks:\n",
    "        print(\"処理する新しいチャンクが見つかりませんでした。既存のデータベースを使用します。\")\n",
    "        return collection\n",
    "\n",
    "    print(f\"{len(all_chunks)} 個のチャンクを埋め込み、データベースに追加中...\")\n",
    "    collection.add(\n",
    "        documents=all_chunks,\n",
    "        metadatas=all_metadatas,\n",
    "        ids=all_ids\n",
    "    )\n",
    "    print(f\"ベクトルデータベース '{collection_name}' が '{persist_directory}' に正常に更新されました。現在のドキュメント数: {collection.count()}\")\n",
    "    return collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55915e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- RAGチャットの実装 ---\n",
    "\n",
    "def rag_chat(collection, query, top_k=3):\n",
    "    \"\"\"\n",
    "    RAG (Retrieval Augmented Generation) を用いた単一応答機能\n",
    "    \"\"\"\n",
    "    if collection.count() == 0:\n",
    "        return \"データベースが空のため、質問に答えることができません。\"\n",
    "\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=top_k\n",
    "    )\n",
    "\n",
    "    retrieved_documents = results['documents'][0]\n",
    "    if not retrieved_documents:\n",
    "        return \"関連するドキュメントが見つかりませんでした。質問の仕方を変えてみてください。\"\n",
    "\n",
    "    context = \"\\n\".join(retrieved_documents)\n",
    "    \n",
    "    print(\"\\n--- 検索されたドキュメント ---\")\n",
    "    for i, doc in enumerate(retrieved_documents):\n",
    "        print(f\"ドキュメント {i+1} (ソース: {results['metadatas'][0][i]['source']}):\")\n",
    "        print(doc[:200].replace('\\n', ' ') + \"...\") \n",
    "        print(\"-\" * 20)\n",
    "\n",
    "    prompt = f\"\"\"以下の情報に基づいて質問に答えてください。質問に関連しない情報は無視してください。\n",
    "    情報:\n",
    "    {context}\n",
    "\n",
    "    質問: {query}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    print(\"\\n--- Geminiモデルが応答を生成中 ---\")\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=chat_model, \n",
    "            contents=prompt\n",
    "            )\n",
    "\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Geminiモデルからの応答生成中にエラーが発生しました: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f9661d",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646dd1d4",
   "metadata": {},
   "source": [
    "### データベースの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87c83564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ディレクトリ '../data/1020test/raw' 内のファイルを検索中...\n",
      "ファイル 'example_doc2.md' を読み込み中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Client.__del__ at 0x000001E1AC6D0180>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ryoic\\repository\\251012_dev.git\\.venv\\Lib\\site-packages\\google\\genai\\client.py\", line 400, in __del__\n",
      "    self.close()\n",
      "  File \"c:\\Users\\ryoic\\repository\\251012_dev.git\\.venv\\Lib\\site-packages\\google\\genai\\client.py\", line 386, in close\n",
      "    self._api_client.close()\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Client' object has no attribute '_api_client'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ファイル 'example_doc3.md' を読み込み中...\n",
      "\n",
      "--- 複数のドキュメントからベクトルデータベースを作成または更新 ---\n",
      "ベクトルデータベース '1020_test' を作成中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryoic\\repository\\251012_dev.git\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "既存のコレクション '1020_test' には 0 個のドキュメントがあります。\n",
      "ファイル '../data/1020test/raw\\example_doc2.md' を 1 個のチャンクに分割しました。\n",
      "ファイル '../data/1020test/raw\\example_doc3.md' を 1 個のチャンクに分割しました。\n",
      "2 個のチャンクを埋め込み、データベースに追加中...\n",
      "ベクトルデータベース '1020_test' が '../data/1020test/vector_store' に正常に更新されました。現在のドキュメント数: 2\n",
      "ベクトルデータベースの準備が完了しました。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "documents_to_process = []\n",
    "print(f\"ディレクトリ '{input_dir}' 内のファイルを検索中...\")\n",
    "for filename in os.listdir(input_dir):\n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        if filename.lower().endswith(('.pdf', '.md')):\n",
    "            print(f\"ファイル '{filename}' を読み込み中...\")\n",
    "            content = load_document(file_path)\n",
    "            if content:\n",
    "                documents_to_process.append((file_path, content))\n",
    "            else:\n",
    "                print(f\"警告: ファイル '{file_path}' の読み込みに失敗したか、内容が空です。\")\n",
    "        else:\n",
    "            print(f\"スキップ: サポートされていないファイル形式 '{filename}'\")\n",
    "\n",
    "if not documents_to_process:\n",
    "    print(f\"'{input_dir}' ディレクトリに処理可能なPDFまたはMarkdownファイルが見つかりませんでした。\")\n",
    "    unified_collection = None # データベースが作成できなかったことを示す\n",
    "else:\n",
    "    print(\"\\n--- 複数のドキュメントからベクトルデータベースを作成または更新 ---\")\n",
    "    unified_collection = create_vector_database(documents_to_process, collection_name=collection_name, persist_directory=persist_db_dir)\n",
    "    print(\"ベクトルデータベースの準備が完了しました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccf1019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 質問と応答 ---\n",
      "\n",
      "--- 検索されたドキュメント ---\n",
      "ドキュメント 1 (ソース: example_doc2.md):\n",
      "<h1>Gemini APIの概要</h1> <p>Gemini APIは、Googleの最新のマルチモーダルAIモデルであるGeminiモデルへのアクセスを提供します。 これは、テキスト、画像、音声、動画などの異なるタイプの情報を理解し、処理することができます。</p> <h2>主な機能</h2> <ul> <li><strong>柔軟なモデル:</strong> さまざまな規模のモデル（Ult...\n",
      "--------------------\n",
      "ドキュメント 2 (ソース: example_doc3.md):\n",
      "<h1>ベクトルデータベースについて</h1> <p>ベクトルデータベースは、データを高次元のベクトル表現として保存し、類似性検索を効率的に行うためのデータベースです。 特にAIや機械学習の分野で、意味的に関連する情報を素早く見つけ出すのに役立ちます。</p> <h2>利点</h2> <ul> <li><strong>高速な類似性検索:</strong> ユークリッド距離やコサイン類似度などの指標...\n",
      "--------------------\n",
      "\n",
      "--- Geminiモデルが応答を生成中 ---\n",
      "\n",
      "質問: Gemini APIの主な機能は何ですか？RAGについても説明してください。\n",
      "応答: Gemini APIの主な機能は以下の通りです。\n",
      "\n",
      "*   **柔軟なモデル:** さまざまな規模のモデル（Ultra, Pro, Nano）があります。\n",
      "*   **マルチモーダル:** テキストだけでなく、画像などの入力も扱えます。\n",
      "*   **高度な推論:** 複雑な問題解決能力を持っています。\n",
      "\n",
      "RAG (Retrieval Augmented Generation) は、外部知識ベースから情報を取得し、その情報に基づいて応答を生成するAIシステムです。これにより、モデルはより正確で最新の情報を利用できます。質問応答システムによく用いられます。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if unified_collection and unified_collection.count() > 0:\n",
    "    print(\"\\n--- 質問と応答 ---\")\n",
    "    # ここに質問文を入力してください\n",
    "    user_query = \"Gemini APIの主な機能は何ですか？RAGについても説明してください。\" \n",
    "    \n",
    "    response = rag_chat(unified_collection, user_query)\n",
    "    print(f\"\\n質問: {user_query}\")\n",
    "    print(f\"応答: {response}\")\n",
    "else:\n",
    "    print(\"ベクトルデータベースが利用できません。データベースを作成または更新してください。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dddce07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
